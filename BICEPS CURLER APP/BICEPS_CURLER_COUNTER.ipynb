{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ebc0040-30f5-4fd4-af9d-c6ee65ed1321",
   "metadata": {},
   "source": [
    "# INSTALLATION AND IMPORTATION OF DEPENDENCIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da8e3499-f8b2-4f19-ba00-3691d1054edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"]=\"python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "085cd540-1b1f-45ba-affc-4e497a22cc0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in c:\\users\\emryz\\anaconda3\\envs\\python311\\lib\\site-packages (0.10.14)\n",
      "Requirement already satisfied: absl-py in c:\\users\\emryz\\anaconda3\\envs\\python311\\lib\\site-packages (from mediapipe) (2.1.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\emryz\\anaconda3\\envs\\python311\\lib\\site-packages (from mediapipe) (24.2.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\emryz\\anaconda3\\envs\\python311\\lib\\site-packages (from mediapipe) (24.3.25)\n",
      "Requirement already satisfied: jax in c:\\users\\emryz\\anaconda3\\envs\\python311\\lib\\site-packages (from mediapipe) (0.4.34)\n",
      "Requirement already satisfied: jaxlib in c:\\users\\emryz\\anaconda3\\envs\\python311\\lib\\site-packages (from mediapipe) (0.4.34)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\emryz\\anaconda3\\envs\\python311\\lib\\site-packages (from mediapipe) (3.9.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\emryz\\anaconda3\\envs\\python311\\lib\\site-packages (from mediapipe) (2.1.2)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\emryz\\anaconda3\\envs\\python311\\lib\\site-packages (from mediapipe) (4.10.0.84)\n",
      "Requirement already satisfied: protobuf<5,>=4.25.3 in c:\\users\\emryz\\anaconda3\\envs\\python311\\lib\\site-packages (from mediapipe) (4.25.5)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in c:\\users\\emryz\\anaconda3\\envs\\python311\\lib\\site-packages (from mediapipe) (0.5.0)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\emryz\\anaconda3\\envs\\python311\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in c:\\users\\emryz\\anaconda3\\envs\\python311\\lib\\site-packages (from jax->mediapipe) (0.5.0)\n",
      "Requirement already satisfied: opt-einsum in c:\\users\\emryz\\anaconda3\\envs\\python311\\lib\\site-packages (from jax->mediapipe) (3.4.0)\n",
      "Requirement already satisfied: scipy>=1.10 in c:\\users\\emryz\\anaconda3\\envs\\python311\\lib\\site-packages (from jax->mediapipe) (1.14.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\emryz\\anaconda3\\envs\\python311\\lib\\site-packages (from matplotlib->mediapipe) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\emryz\\anaconda3\\envs\\python311\\lib\\site-packages (from matplotlib->mediapipe) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\emryz\\anaconda3\\envs\\python311\\lib\\site-packages (from matplotlib->mediapipe) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\emryz\\anaconda3\\envs\\python311\\lib\\site-packages (from matplotlib->mediapipe) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\emryz\\anaconda3\\envs\\python311\\lib\\site-packages (from matplotlib->mediapipe) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\emryz\\anaconda3\\envs\\python311\\lib\\site-packages (from matplotlib->mediapipe) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\emryz\\anaconda3\\envs\\python311\\lib\\site-packages (from matplotlib->mediapipe) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\emryz\\anaconda3\\envs\\python311\\lib\\site-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\emryz\\anaconda3\\envs\\python311\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\emryz\\anaconda3\\envs\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe\n",
    "# ! pip uninstall mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66a6d86c-9476-4d42-bc30-2946c68f0336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: protobuf\n",
      "Version: 4.25.5\n",
      "Summary: \n",
      "Home-page: https://developers.google.com/protocol-buffers/\n",
      "Author: protobuf@googlegroups.com\n",
      "Author-email: protobuf@googlegroups.com\n",
      "License: 3-Clause BSD License\n",
      "Location: C:\\Users\\emryz\\anaconda3\\envs\\python311\\Lib\\site-packages\n",
      "Requires: \n",
      "Required-by: mediapipe\n"
     ]
    }
   ],
   "source": [
    "!pip show protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d1d1ce5-b41f-4a1f-b78b-c781a87f8be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in c:\\users\\emryz\\anaconda3\\envs\\python311\\lib\\site-packages (0.10.14)\n",
      "Requirement already satisfied: absl-py in c:\\users\\emryz\\anaconda3\\envs\\python311\\lib\\site-packages (from mediapipe) (2.1.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\emryz\\anaconda3\\envs\\python311\\lib\\site-packages (from mediapipe) (24.2.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\emryz\\anaconda3\\envs\\python311\\lib\\site-packages (from mediapipe) (24.3.25)\n",
      "Requirement already satisfied: jax in c:\\users\\emryz\\anaconda3\\envs\\python311\\lib\\site-packages (from mediapipe) (0.4.34)\n",
      "Requirement already satisfied: jaxlib in c:\\users\\emryz\\anaconda3\\envs\\python311\\lib\\site-packages (from mediapipe) (0.4.34)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\emryz\\anaconda3\\envs\\python311\\lib\\site-packages (from mediapipe) (3.9.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\emryz\\anaconda3\\envs\\python311\\lib\\site-packages (from mediapipe) (2.1.2)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\emryz\\anaconda3\\envs\\python311\\lib\\site-packages (from mediapipe) (4.10.0.84)\n",
      "Requirement already satisfied: protobuf<5,>=4.25.3 in c:\\users\\emryz\\anaconda3\\envs\\python311\\lib\\site-packages (from mediapipe) (4.25.5)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in c:\\users\\emryz\\anaconda3\\envs\\python311\\lib\\site-packages (from mediapipe) (0.5.0)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\emryz\\anaconda3\\envs\\python311\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in c:\\users\\emryz\\anaconda3\\envs\\python311\\lib\\site-packages (from jax->mediapipe) (0.5.0)\n",
      "Requirement already satisfied: opt-einsum in c:\\users\\emryz\\anaconda3\\envs\\python311\\lib\\site-packages (from jax->mediapipe) (3.4.0)\n",
      "Requirement already satisfied: scipy>=1.10 in c:\\users\\emryz\\anaconda3\\envs\\python311\\lib\\site-packages (from jax->mediapipe) (1.14.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\emryz\\anaconda3\\envs\\python311\\lib\\site-packages (from matplotlib->mediapipe) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\emryz\\anaconda3\\envs\\python311\\lib\\site-packages (from matplotlib->mediapipe) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\emryz\\anaconda3\\envs\\python311\\lib\\site-packages (from matplotlib->mediapipe) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\emryz\\anaconda3\\envs\\python311\\lib\\site-packages (from matplotlib->mediapipe) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\emryz\\anaconda3\\envs\\python311\\lib\\site-packages (from matplotlib->mediapipe) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\emryz\\anaconda3\\envs\\python311\\lib\\site-packages (from matplotlib->mediapipe) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\emryz\\anaconda3\\envs\\python311\\lib\\site-packages (from matplotlib->mediapipe) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\emryz\\anaconda3\\envs\\python311\\lib\\site-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\emryz\\anaconda3\\envs\\python311\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\emryz\\anaconda3\\envs\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c405adf6-7f79-4cbe-8dc1-db0e516e50ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Errors with protobuf [\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"]=\"python\" corrected by putting it in system variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "726ae30b-a5c0-4f5a-9fc7-e40275cc5782",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from mediapipe import solutions\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1566b8b8-bf94-4eb4-a356-d6a518eb9309",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret,frame = cap.read()\n",
    "\n",
    "    cv.imshow(\"Media Pipe\",frame)\n",
    "    if cv.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv.release()\n",
    "cap.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "653374d7-cf19-4f5c-83ed-6ff9fb38b39a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'mediapipe.python.solutions.drawing_utils' from 'C:\\\\Users\\\\emryz\\\\anaconda3\\\\envs\\\\tensorflow\\\\lib\\\\site-packages\\\\mediapipe\\\\python\\\\solutions\\\\drawing_utils.py'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp_drawing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe8b531-90cf-495b-a4ee-e49dc1f2ab31",
   "metadata": {},
   "source": [
    "# MAKE DETECTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a833331-528b-43da-a59e-62accaca7565",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5,min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret,frame = cap.read()\n",
    "\n",
    "        image = cv.cvtColor(frame,cv.COLOR_BGR2RGB)\n",
    "        image.flags.writeable=False\n",
    "\n",
    "        #Make detection\n",
    "        results = pose.process(image)\n",
    "\n",
    "        image.flags.writeable=True\n",
    "        image = cv.cvtColor(image,cv.COLOR_RGB2BGR)\n",
    "\n",
    "        mp_drawing.draw_landmarks(image,results.pose_landmarks,mp_pose.POSE_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(color=(245,117,66), thickness=2,circle_radius=2),\n",
    "                                  mp_drawing.DrawingSpec(color=(245,66,230), thickness=2,circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "    \n",
    "        cv.imshow(\"Media Pipe\",image)\n",
    "        if cv.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1c897fc7-2988-4db4-b2c2-16a5d064df17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "imshow(winname, mat) -> None\n",
       ".   @brief Displays an image in the specified window.\n",
       ".   \n",
       ".   The function imshow displays an image in the specified window. If the window was created with the\n",
       ".   cv::WINDOW_AUTOSIZE flag, the image is shown with its original size, however it is still limited by the screen resolution.\n",
       ".   Otherwise, the image is scaled to fit the window. The function may scale the image, depending on its depth:\n",
       ".   \n",
       ".   -   If the image is 8-bit unsigned, it is displayed as is.\n",
       ".   -   If the image is 16-bit unsigned, the pixels are divided by 256. That is, the\n",
       ".       value range [0,255\\*256] is mapped to [0,255].\n",
       ".   -   If the image is 32-bit or 64-bit floating-point, the pixel values are multiplied by 255. That is, the\n",
       ".       value range [0,1] is mapped to [0,255].\n",
       ".   -   32-bit integer images are not processed anymore due to ambiguouty of required transform.\n",
       ".       Convert to 8-bit unsigned matrix using a custom preprocessing specific to image's context.\n",
       ".   \n",
       ".   If window was created with OpenGL support, cv::imshow also support ogl::Buffer , ogl::Texture2D and\n",
       ".   cuda::GpuMat as input.\n",
       ".   \n",
       ".   If the window was not created before this function, it is assumed creating a window with cv::WINDOW_AUTOSIZE.\n",
       ".   \n",
       ".   If you need to show an image that is bigger than the screen resolution, you will need to call namedWindow(\"\", WINDOW_NORMAL) before the imshow.\n",
       ".   \n",
       ".   @note This function should be followed by a call to cv::waitKey or cv::pollKey to perform GUI\n",
       ".   housekeeping tasks that are necessary to actually show the given image and make the window respond\n",
       ".   to mouse and keyboard events. Otherwise, it won't display the image and the window might lock up.\n",
       ".   For example, **waitKey(0)** will display the window infinitely until any keypress (it is suitable\n",
       ".   for image display). **waitKey(25)** will display a frame and wait approximately 25 ms for a key\n",
       ".   press (suitable for displaying a video frame-by-frame). To remove the window, use cv::destroyWindow.\n",
       ".   \n",
       ".   @note [__Windows Backend Only__] Pressing Ctrl+C will copy the image to the clipboard. Pressing Ctrl+S will show a dialog to save the image.\n",
       ".   @note [__Wayland Backend Only__] Supoorting format is extended.\n",
       ".   -   If the image is 8-bit signed, the pixels are biased by 128. That is, the\n",
       ".       value range [-128,127] is mapped to [0,255].\n",
       ".   -   If the image is 16-bit signed, the pixels are divided by 256 and biased by 128. That is, the\n",
       ".       value range [-32768,32767] is mapped to [0,255].\n",
       ".   \n",
       ".   @param winname Name of the window.\n",
       ".   @param mat Image to be shown.\n",
       "\u001b[1;31mType:\u001b[0m      builtin_function_or_method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11e22234-822f-4216-a940-d20333a8db22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({(0, 1),\n",
       "           (0, 4),\n",
       "           (1, 2),\n",
       "           (2, 3),\n",
       "           (3, 7),\n",
       "           (4, 5),\n",
       "           (5, 6),\n",
       "           (6, 8),\n",
       "           (9, 10),\n",
       "           (11, 12),\n",
       "           (11, 13),\n",
       "           (11, 23),\n",
       "           (12, 14),\n",
       "           (12, 24),\n",
       "           (13, 15),\n",
       "           (14, 16),\n",
       "           (15, 17),\n",
       "           (15, 19),\n",
       "           (15, 21),\n",
       "           (16, 18),\n",
       "           (16, 20),\n",
       "           (16, 22),\n",
       "           (17, 19),\n",
       "           (18, 20),\n",
       "           (23, 24),\n",
       "           (23, 25),\n",
       "           (24, 26),\n",
       "           (25, 27),\n",
       "           (26, 28),\n",
       "           (27, 29),\n",
       "           (27, 31),\n",
       "           (28, 30),\n",
       "           (28, 32),\n",
       "           (29, 31),\n",
       "           (30, 32)})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(results)\n",
    "results.pose_landmarks\n",
    "mp_pose.POSE_CONNECTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf1a7c2-3ba3-425f-bb2f-cfbcd7a10c5b",
   "metadata": {},
   "source": [
    "# DETERMINE JOINTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b420b0-af02-4507-aa9d-fc6112172521",
   "metadata": {},
   "source": [
    "<img src=\"https://ai.google.dev/static/mediapipe/images/solutions/pose_landmarks_index.png\" style=\"height:300px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243af398-ac92-490f-82ca-d579caa4eb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5,min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret,frame = cap.read()\n",
    "\n",
    "        image = cv.cvtColor(frame,cv.COLOR_BGR2RGB)\n",
    "        image.flags.writeable=False\n",
    "\n",
    "        #Make detection\n",
    "        results = pose.process(image)\n",
    "\n",
    "        image.flags.writeable=True\n",
    "        image = cv.cvtColor(image,cv.COLOR_RGB2BGR)\n",
    "\n",
    "        #Extract landmark\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        #Render detection\n",
    "        mp_drawing.draw_landmarks(image,results.pose_landmarks,mp_pose.POSE_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(color=(245,117,66), thickness=2,circle_radius=2),\n",
    "                                  mp_drawing.DrawingSpec(color=(245,66,230), thickness=2,circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "    \n",
    "        cv.imshow(\"Media Pipe\",image)\n",
    "        if cv.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0a5b4db1-d597-450d-95e6-c4abdee9751d",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks = results.pose_landmarks.landmark\n",
    "left_shoulder_coordinate = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value]\n",
    "left_wrist_coordinate = landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value]\n",
    "left_elbow_coordinate = landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "990fc839-4bcb-427b-b9f7-7e75fb21cb7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<PoseLandmark.NOSE: 0>,\n",
       " <PoseLandmark.LEFT_EYE_INNER: 1>,\n",
       " <PoseLandmark.LEFT_EYE: 2>,\n",
       " <PoseLandmark.LEFT_EYE_OUTER: 3>,\n",
       " <PoseLandmark.RIGHT_EYE_INNER: 4>,\n",
       " <PoseLandmark.RIGHT_EYE: 5>,\n",
       " <PoseLandmark.RIGHT_EYE_OUTER: 6>,\n",
       " <PoseLandmark.LEFT_EAR: 7>,\n",
       " <PoseLandmark.RIGHT_EAR: 8>,\n",
       " <PoseLandmark.MOUTH_LEFT: 9>,\n",
       " <PoseLandmark.MOUTH_RIGHT: 10>,\n",
       " <PoseLandmark.LEFT_SHOULDER: 11>,\n",
       " <PoseLandmark.RIGHT_SHOULDER: 12>,\n",
       " <PoseLandmark.LEFT_ELBOW: 13>,\n",
       " <PoseLandmark.RIGHT_ELBOW: 14>,\n",
       " <PoseLandmark.LEFT_WRIST: 15>,\n",
       " <PoseLandmark.RIGHT_WRIST: 16>,\n",
       " <PoseLandmark.LEFT_PINKY: 17>,\n",
       " <PoseLandmark.RIGHT_PINKY: 18>,\n",
       " <PoseLandmark.LEFT_INDEX: 19>,\n",
       " <PoseLandmark.RIGHT_INDEX: 20>,\n",
       " <PoseLandmark.LEFT_THUMB: 21>,\n",
       " <PoseLandmark.RIGHT_THUMB: 22>,\n",
       " <PoseLandmark.LEFT_HIP: 23>,\n",
       " <PoseLandmark.RIGHT_HIP: 24>,\n",
       " <PoseLandmark.LEFT_KNEE: 25>,\n",
       " <PoseLandmark.RIGHT_KNEE: 26>,\n",
       " <PoseLandmark.LEFT_ANKLE: 27>,\n",
       " <PoseLandmark.RIGHT_ANKLE: 28>,\n",
       " <PoseLandmark.LEFT_HEEL: 29>,\n",
       " <PoseLandmark.RIGHT_HEEL: 30>,\n",
       " <PoseLandmark.LEFT_FOOT_INDEX: 31>,\n",
       " <PoseLandmark.RIGHT_FOOT_INDEX: 32>]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(mp_pose.PoseLandmark)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c828dd30-c5cf-43e3-b38c-1530c77b241e",
   "metadata": {},
   "source": [
    "# CALCULATE ANGLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "515cf462-0fbd-4e44-8e80-af9dee41b06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle_arctan_method(a,b,c):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "\n",
    "    radians = np.arctan2( c[1]-b[1] , c[0] - b[0] ) - np.arctan2( a[1]-b[1] , a[0] - b[0] )\n",
    "    ang_deg = np.abs(radians * (180/np.pi))\n",
    "\n",
    "    if ang_deg > 180:\n",
    "        ang_deg = 360 - ang_deg\n",
    "    return ang_deg\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d2258994-7aba-415b-a608-37eb8aa89241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156.51191513540283\n"
     ]
    }
   ],
   "source": [
    "shoulder = [left_shoulder_coordinate.x,left_shoulder_coordinate.y]\n",
    "wrist = [left_wrist_coordinate.x,left_wrist_coordinate.y]\n",
    "elbow = [left_elbow_coordinate.x,left_elbow_coordinate.y]\n",
    "\n",
    "print(calculate_angle_arctan_method(shoulder,elbow,wrist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "321c14de-0919-4866-a33b-1e8d6b05980f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176.79613619700362\n"
     ]
    }
   ],
   "source": [
    "# will come back to this\n",
    "def calculate_angle_supplementary(a,b,c):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "\n",
    "    angle_EW = np.arctan2( c[1]-b[1] , c[0] - b[0] )\n",
    "    angle_ES =  np.arctan2( a[1]-b[1] , a[0] - b[0] )\n",
    "    \n",
    "    deg_angle_EW = angle_EW * (180/np.pi)\n",
    "    deg_angle_ES = angle_ES * (180/np.pi)\n",
    "\n",
    "    ang_deg = 180 - (deg_angle_EW + deg_angle_ES)\n",
    "\n",
    "    return ang_deg\n",
    "    \n",
    "print(calculate_angle_supplementary(shoulder,elbow,wrist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d16036-972a-47b1-9c8e-69ad168888b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5,min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret,frame = cap.read()\n",
    "\n",
    "        image = cv.cvtColor(frame,cv.COLOR_BGR2RGB)\n",
    "        image.flags.writeable=False\n",
    "\n",
    "        #Make detection\n",
    "        results = pose.process(image)\n",
    "\n",
    "        image.flags.writeable=True\n",
    "        image = cv.cvtColor(image,cv.COLOR_RGB2BGR)\n",
    "\n",
    "\n",
    "        #Render detection\n",
    "        mp_drawing.draw_landmarks(image,results.pose_landmarks,mp_pose.POSE_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(color=(245,117,66), thickness=2,circle_radius=2),\n",
    "                                  mp_drawing.DrawingSpec(color=(245,66,230), thickness=2,circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        #Extract landmark\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "             # Get coordinates\n",
    "            shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            #calculate angle\n",
    "            angle = calculate_angle_arctan_method(shoulder,elbow,wrist)\n",
    "            \n",
    "            cv.putText(image, str(angle), \n",
    "                       tuple(np.multiply(elbow, [640,480]).astype(int)), \n",
    "                       cv.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                      (0, 0, 255), 2, cv.LINE_AA, False)\n",
    "            # print(angle)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    \n",
    "        cv.imshow(\"Media Pipe\",image)\n",
    "        if cv.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7a8bca6e-963f-4062-8d31-58507e621e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x: 0.8723006\n",
       "y: 1.2008727\n",
       "z: -0.5168947\n",
       "visibility: 0.071356505"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d139b35c-a19d-4a0e-8276-826495329721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 640, 3)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd3d6ec-f4c6-4739-a9ae-ac7496b6b42a",
   "metadata": {},
   "source": [
    "# CURL COUNTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d1844791-5494-4e14-b138-8d1c1c340213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "counter = 0\n",
    "stage = None\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5,min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret,frame = cap.read()\n",
    "\n",
    "        image = cv.cvtColor(frame,cv.COLOR_BGR2RGB)\n",
    "        image.flags.writeable=False\n",
    "\n",
    "        #Make detection\n",
    "        results = pose.process(image)\n",
    "\n",
    "        image.flags.writeable=True\n",
    "        image = cv.cvtColor(image,cv.COLOR_RGB2BGR)\n",
    "\n",
    "\n",
    "        #Render detection\n",
    "        mp_drawing.draw_landmarks(image,results.pose_landmarks,mp_pose.POSE_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(color=(245,117,66), thickness=2,circle_radius=2),\n",
    "                                  mp_drawing.DrawingSpec(color=(245,66,230), thickness=2,circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        #Extract landmark\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "             # Get coordinates\n",
    "            shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            #calculate angle\n",
    "            angle = calculate_angle_arctan_method(shoulder,elbow,wrist)\n",
    "            \n",
    "            cv.putText(image, str(angle), \n",
    "                       tuple(np.multiply(elbow, [640,480]).astype(int)), \n",
    "                       cv.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                      (0, 0, 255), 2, cv.LINE_AA, False)\n",
    "\n",
    "            if angle > 140:\n",
    "                stage = \"down\"\n",
    "\n",
    "            if angle < 45 and stage == \"down\":\n",
    "                counter += 1\n",
    "                stage = \"up\"\n",
    "                print(counter)\n",
    "                \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        cv.rectangle(image,(0,0),(225,73),(0, 0, 240),-1)\n",
    "        #rep data\n",
    "        cv.putText(image, \"REPS\", \n",
    "                      (15,12), \n",
    "                       cv.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                      (0, 0, 0), 1, cv.LINE_AA, False)\n",
    "        cv.putText(image, str(counter), \n",
    "                      (10,60), \n",
    "                       cv.FONT_HERSHEY_SIMPLEX, 2,\n",
    "                      (255, 255, 255), 2, cv.LINE_AA, False)\n",
    "\n",
    "        #stage data\n",
    "        cv.putText(image, \"LOCATION\", \n",
    "                      (65,12), \n",
    "                       cv.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                      (0, 0, 0), 1, cv.LINE_AA, False)\n",
    "        cv.putText(image, str(stage), \n",
    "                      (60,60), \n",
    "                       cv.FONT_HERSHEY_SIMPLEX, 2,\n",
    "                      (255, 255, 255), 2, cv.LINE_AA, False)\n",
    "        \n",
    "        cv.imshow(\"Media Pipe\",image)\n",
    "        if cv.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbd78ba-e6dd-40f5-b745-adda32f0f0ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e26bf2-c302-4109-918a-7f54ae2dfc26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4146ede9-0498-4584-8bb4-920512dce056",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
